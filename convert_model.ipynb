{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import seaborn as sns\n",
    "#import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import PIL\n",
    "#import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "# from sklearn import datasets\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the name of all the labels\n",
    "home_path = '/home/bowen/Documents/Ecomed/'\n",
    "data_path = '/home/bowen/Documents/Ecomed/dataset'\n",
    "class_names = os.listdir(data_path)\n",
    "class_names = [\"pharmaceutical\", \"sharps\", \"trace_chemo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6004 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up data generators that can read images from our dataset into Keras.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "data_generator = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=6000,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = '/home/bowen/Documents/Ecomed/models'\n",
    "convert_model_folder = model_path + '/convert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.MobileNet(include_top=False, input_shape=[224, 224, 3], weights='imagenet')\n",
    "x = mobilenet.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "\n",
    "# Combine feature layers with our new output layers.\n",
    "model = tf.keras.Model(inputs=mobilenet.input, outputs=preds)\n",
    "# defintion of optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "# opt = tf.keras.optimizers.SGD(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_path = os.path.join(model_folder, 'model_success.h5')\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneSave Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_folder, '1551769465')\n",
    "model = tf.contrib.saved_model.load_keras_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.05919514049694606, 0.9876748789635441]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:2'):\n",
    "    result = model.evaluate_generator(data_generator)\n",
    "print(model.metrics_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "# Save tf.keras model in HDF5 format.\n",
    "# keras_file = \"/home/bowen/Documents/Ecomed/models/convert/model_success_middle.h5\"\n",
    "# tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = os.path.join('/home/bowen/Documents/Ecomed/models', '1551769465')\n",
    "# model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/bowen/Documents/Ecomed/models/1551769465/variables/variables\n",
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n",
      "INFO:tensorflow:input tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_2\n",
      "INFO:tensorflow: tensor name: input_2:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n",
      "INFO:tensorflow:output tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_19\n",
      "INFO:tensorflow: tensor name: dense_19/Softmax:0, shape: (-1, 3), type: DT_FLOAT\n",
      "INFO:tensorflow:Restoring parameters from /home/bowen/Documents/Ecomed/models/1551769465/variables/variables\n",
      "INFO:tensorflow:Froze 143 variables.\n",
      "INFO:tensorflow:Converted 143 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Converting from keras is super simple, we simply point a tfliteconverter to our model!\n",
    "model_path = os.path.join(model_folder, '1551769465')\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_saved_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size is 23298 KBytes.\n"
     ]
    }
   ],
   "source": [
    "# Specify where to save the new model.\n",
    "tflite_model_path = os.path.join(convert_model_folder, 'model.tflite')\n",
    "# Write the bytes of the model file to our drive.\n",
    "open(tflite_model_path, \"wb\").write(tflite_model)\n",
    "# Let's just check the size of the model.\n",
    "print(\"Model size is %d KBytes.\" % (os.stat(tflite_model_path).st_size/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the tf.lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'input_2', 'index': 106, 'shape': array([  1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n",
      "[{'name': 'dense_19/Softmax', 'index': 102, 'shape': array([1, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n"
     ]
    }
   ],
   "source": [
    "# Create a tflite interpreter, this is the part of tflite that actually runs models.\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path=tflite_model_path)\n",
    "# Allocate memory for the all the weight tensors and such.\n",
    "interpreter.allocate_tensors()\n",
    "# Get input and output tensor information.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interpreter(input_data):\n",
    "#     interpreter.reset_all_variables()\n",
    "    # Set tensor specifies the input to the model.\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    # Invoke is used to run the input through the model.\n",
    "    interpreter.invoke()\n",
    "    # We have to use get_tensor to load the output.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return np.argmax(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples 6000\n",
      "accuracy 0.9858333333333333\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels = data_generator.next()\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, sample in enumerate(test_data):\n",
    "    input_data = sample[tf.newaxis, ...]\n",
    "    predict = run_interpreter(input_data)\n",
    "    if predict == int(test_labels[i]):\n",
    "        correct +=1\n",
    "    total +=1\n",
    "print(\"Total Samples\", total)\n",
    "print(\"accuracy\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
