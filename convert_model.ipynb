{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import seaborn as sns\n",
    "#import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import PIL\n",
    "#import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "# from sklearn import datasets\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background',\n",
       " 'needles_I_V_Cannula',\n",
       " 'needles_safety',\n",
       " 'needles_black',\n",
       " 'needles_yellow',\n",
       " 'garbage_gloves',\n",
       " 'syringes_large',\n",
       " 'garbage_alcohol_pad',\n",
       " 'needles_butterfly',\n",
       " 'syringes_small',\n",
       " 'needles_pink',\n",
       " 'syringes_1ml',\n",
       " 'garbage_cotton_ball',\n",
       " 'needles_blood_collection']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of all the labels\n",
    "home_path = '/home/bowen/Documents/Ecomed/'\n",
    "data_path = '/home/bowen/Documents/Ecomed/dataset'\n",
    "class_names = os.listdir(data_path)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2033 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up data generators that can read images from our dataset into Keras.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "data_generator = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1000,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('/home/bowen/Documents/Ecomed/models', '1550686223')\n",
    "# model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/bowen/Documents/Ecomed/models/1550686223/variables/variables\n",
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n",
      "INFO:tensorflow:input tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: input_7\n",
      "INFO:tensorflow: tensor name: input_7:0, shape: (-1, 224, 224, 3), type: DT_FLOAT\n",
      "INFO:tensorflow:output tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: Logits\n",
      "INFO:tensorflow: tensor name: Logits/Softmax:0, shape: (-1, 1000), type: DT_FLOAT\n",
      "INFO:tensorflow:Restoring parameters from /home/bowen/Documents/Ecomed/models/1550686223/variables/variables\n",
      "INFO:tensorflow:Froze 262 variables.\n",
      "INFO:tensorflow:Converted 262 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Converting from keras is super simple, we simply point a tfliteconverter to our model!\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_saved_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size is 13973 KBytes.\n"
     ]
    }
   ],
   "source": [
    "# Specify where to save the new model.\n",
    "tflite_model_path = os.path.join('/home/bowen/Documents/Ecomed/models', 'model.tflite')\n",
    "# Write the bytes of the model file to our drive.\n",
    "open(tflite_model_path, \"wb\").write(tflite_model)\n",
    "# Let's just check the size of the model.\n",
    "print(\"Model size is %d KBytes.\" % (os.stat(tflite_model_path).st_size/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'input_7', 'index': 181, 'shape': array([  1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n",
      "[{'name': 'Logits/Softmax', 'index': 9, 'shape': array([   1, 1000], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n"
     ]
    }
   ],
   "source": [
    "# Create a tflite interpreter, this is the part of tflite that actually runs models.\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path=tflite_model_path)\n",
    "# Allocate memory for the all the weight tensors and such.\n",
    "interpreter.allocate_tensors()\n",
    "# Get input and output tensor information.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_interpreter(input_data):\n",
    "    interpreter.reset_all_variables()\n",
    "    # Set tensor specifies the input to the model.\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    # Invoke is used to run the input through the model.\n",
    "    interpreter.invoke()\n",
    "    # We have to use get_tensor to load the output.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return np.argmax(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = data_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples 1000\n",
      "accuracy 0.992\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, sample in enumerate(test_data):\n",
    "    input_data = sample[tf.newaxis, ...]\n",
    "    predict = run_interpreter(input_data)\n",
    "    if predict == int(test_labels[i]):\n",
    "        correct +=1\n",
    "    total +=1\n",
    "print(\"Total Samples\", total)\n",
    "print(\"accuracy\", correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
