{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2fUwme2-yoI"
   },
   "source": [
    "This script is aiming to find the proper script to make a classicification of the images.\n",
    "\n",
    "# Import pacakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MaQ3V7q_JH6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import PIL\n",
    "#import requests\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# Use in the model\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2hNScPB_hd3"
   },
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiEUOZ-0iGJw"
   },
   "outputs": [],
   "source": [
    "# Get the name of all the labels\n",
    "home_path = '/home/bowen/Documents/Ecomed/'\n",
    "data_path = '/home/bowen/Documents/Ecomed/dataset/dataset_big_crop'\n",
    "# class_names = os.listdir(data_path)\n",
    "class_names = [\"background\", \"pharmaceutical\", \"sharps\", \"trace_chemo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16115 images belonging to 4 classes.\n",
      "Found 16115 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up data generators that can read images from our dataset into Keras.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.5)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=24,\n",
    "        class_mode='binary',\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=24,\n",
    "        class_mode='binary',\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Show several images\n",
    "# data, labels = validation_generator.next()\n",
    "\n",
    "# for i, sample in enumerate(data):\n",
    "#     plt.imshow(sample)\n",
    "#     print(class_names[int(labels[i])])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv-JUmSdAGHp"
   },
   "source": [
    "# MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2410
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2084,
     "status": "ok",
     "timestamp": 1550511319795,
     "user": {
      "displayName": "Bowen Zhang",
      "photoUrl": "https://lh5.googleusercontent.com/-l5MP4uGzaQc/AAAAAAAAAAI/AAAAAAAAAAc/sFxE7kUGmvM/s64/photo.jpg",
      "userId": "01168430711303576671"
     },
     "user_tz": 300
    },
    "id": "DY2DaeG6_xIR",
    "outputId": "0729fd02-0ae4-4b8a-d1c9-c3da8d47fcde"
   },
   "outputs": [],
   "source": [
    "# Import mobilenet\n",
    "# with tf.device('/gpu:' + str(gpu_index)):\n",
    "mobilenet = tf.keras.applications.MobileNet(include_top=False, input_shape=[224, 224, 3], weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 5,854,916\n",
      "Trainable params: 5,833,028\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add new output layers.\n",
    "# with tf.device('/gpu:' + str(gpu_index)):\n",
    "x = mobilenet.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "# Combine feature layers with our new output layers.\n",
    "model = tf.keras.Model(inputs=mobilenet.input, outputs=preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lwdStaxAO1z"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1694926,
     "status": "ok",
     "timestamp": 1550513025124,
     "user": {
      "displayName": "Bowen Zhang",
      "photoUrl": "https://lh5.googleusercontent.com/-l5MP4uGzaQc/AAAAAAAAAAI/AAAAAAAAAAc/sFxE7kUGmvM/s64/photo.jpg",
      "userId": "01168430711303576671"
     },
     "user_tz": 300
    },
    "id": "XgZH4ZHNAIQ0",
    "outputId": "18bc6d7f-39be-4671-acd3-4cd939b5227f"
   },
   "outputs": [],
   "source": [
    "# defintion of optimizer\n",
    "# with tf.device('/gpu:' + str(gpu_index)):\n",
    "# opt = tf.keras.optimizers.SGD(0.001)\n",
    "opt = tf.train.GradientDescentOptimizer(0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1694926,
     "status": "ok",
     "timestamp": 1550513025124,
     "user": {
      "displayName": "Bowen Zhang",
      "photoUrl": "https://lh5.googleusercontent.com/-l5MP4uGzaQc/AAAAAAAAAAI/AAAAAAAAAAc/sFxE7kUGmvM/s64/photo.jpg",
      "userId": "01168430711303576671"
     },
     "user_tz": 300
    },
    "id": "XgZH4ZHNAIQ0",
    "outputId": "18bc6d7f-39be-4671-acd3-4cd939b5227f"
   },
   "outputs": [],
   "source": [
    "# definition of checkpoint\n",
    "# with tf.device('/gpu:' + str(gpu_index)):\n",
    "checkpoint_path = os.path.join(home_path, 'models', 'model_big4', \"model_big4.h5\")\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(os.path.join(home_path + 'models', \"model_new_layer.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaRCvK_7ARDU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "672/672 [==============================] - 418s 622ms/step - loss: 1.0857 - acc: 0.5354 - val_loss: 0.5925 - val_acc: 0.8086\n",
      "Epoch 2/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.4972 - acc: 0.8129 - val_loss: 0.3880 - val_acc: 0.8824\n",
      "Epoch 3/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.3203 - acc: 0.8857 - val_loss: 0.2875 - val_acc: 0.8952\n",
      "Epoch 4/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.2257 - acc: 0.9216 - val_loss: 0.2521 - val_acc: 0.9176\n",
      "Epoch 5/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.1779 - acc: 0.9397 - val_loss: 0.2444 - val_acc: 0.9257\n",
      "Epoch 6/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.1557 - acc: 0.9463 - val_loss: 0.2872 - val_acc: 0.9225\n",
      "Epoch 7/200\n",
      "672/672 [==============================] - 415s 618ms/step - loss: 0.1317 - acc: 0.9546 - val_loss: 0.2561 - val_acc: 0.9258\n",
      "Epoch 8/200\n",
      "672/672 [==============================] - 419s 624ms/step - loss: 0.1210 - acc: 0.9587 - val_loss: 0.2715 - val_acc: 0.9206\n",
      "Epoch 9/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.1070 - acc: 0.9627 - val_loss: 0.2623 - val_acc: 0.9257\n",
      "Epoch 10/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0919 - acc: 0.9686 - val_loss: 0.2594 - val_acc: 0.9262\n",
      "Epoch 11/200\n",
      "672/672 [==============================] - 410s 611ms/step - loss: 0.0864 - acc: 0.9699 - val_loss: 0.2922 - val_acc: 0.9067\n",
      "Epoch 12/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0786 - acc: 0.9731 - val_loss: 0.2622 - val_acc: 0.9208\n",
      "Epoch 13/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0708 - acc: 0.9748 - val_loss: 0.2662 - val_acc: 0.9215\n",
      "Epoch 14/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0730 - acc: 0.9754 - val_loss: 0.2707 - val_acc: 0.9207\n",
      "Epoch 15/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0614 - acc: 0.9806 - val_loss: 0.2709 - val_acc: 0.9307\n",
      "Epoch 16/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0481 - acc: 0.9841 - val_loss: 0.2599 - val_acc: 0.9303\n",
      "Epoch 17/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0474 - acc: 0.9836 - val_loss: 0.2751 - val_acc: 0.9296\n",
      "Epoch 18/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0519 - acc: 0.9827 - val_loss: 0.2911 - val_acc: 0.9234\n",
      "Epoch 19/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0438 - acc: 0.9859 - val_loss: 0.2888 - val_acc: 0.9267\n",
      "Epoch 20/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0415 - acc: 0.9862 - val_loss: 0.2991 - val_acc: 0.9207\n",
      "Epoch 21/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0385 - acc: 0.9874 - val_loss: 0.3033 - val_acc: 0.9256\n",
      "Epoch 22/200\n",
      "672/672 [==============================] - 409s 609ms/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.3093 - val_acc: 0.9285\n",
      "Epoch 23/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0340 - acc: 0.9894 - val_loss: 0.2859 - val_acc: 0.9319\n",
      "Epoch 24/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0369 - acc: 0.9883 - val_loss: 0.3183 - val_acc: 0.9255\n",
      "Epoch 25/200\n",
      "672/672 [==============================] - 414s 616ms/step - loss: 0.0329 - acc: 0.9902 - val_loss: 0.3045 - val_acc: 0.9291\n",
      "Epoch 26/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0299 - acc: 0.9908 - val_loss: 0.3231 - val_acc: 0.9236\n",
      "Epoch 27/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.3077 - val_acc: 0.9314\n",
      "Epoch 28/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0257 - acc: 0.9922 - val_loss: 0.3327 - val_acc: 0.9280\n",
      "Epoch 29/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0231 - acc: 0.9926 - val_loss: 0.3262 - val_acc: 0.9306\n",
      "Epoch 30/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.3394 - val_acc: 0.9275\n",
      "Epoch 31/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0221 - acc: 0.9924 - val_loss: 0.3380 - val_acc: 0.9271\n",
      "Epoch 32/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.3285 - val_acc: 0.9307\n",
      "Epoch 33/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.3279 - val_acc: 0.9316\n",
      "Epoch 34/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.3313 - val_acc: 0.9278\n",
      "Epoch 35/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0167 - acc: 0.9950 - val_loss: 0.3146 - val_acc: 0.9357\n",
      "Epoch 36/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0191 - acc: 0.9940 - val_loss: 0.3420 - val_acc: 0.9320\n",
      "Epoch 37/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.3318 - val_acc: 0.9306\n",
      "Epoch 38/200\n",
      "672/672 [==============================] - 412s 612ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 0.3440 - val_acc: 0.9296\n",
      "Epoch 39/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0167 - acc: 0.9952 - val_loss: 0.3160 - val_acc: 0.9355\n",
      "Epoch 40/200\n",
      "672/672 [==============================] - 414s 616ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.3457 - val_acc: 0.9299\n",
      "Epoch 41/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.3470 - val_acc: 0.9270\n",
      "Epoch 42/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.3593 - val_acc: 0.9262\n",
      "Epoch 43/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0128 - acc: 0.9961 - val_loss: 0.3312 - val_acc: 0.9304\n",
      "Epoch 44/200\n",
      "672/672 [==============================] - 433s 644ms/step - loss: 0.0132 - acc: 0.9953 - val_loss: 0.3454 - val_acc: 0.9304\n",
      "Epoch 45/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0153 - acc: 0.9957 - val_loss: 0.3419 - val_acc: 0.9321\n",
      "Epoch 46/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.0135 - acc: 0.9956 - val_loss: 0.3427 - val_acc: 0.9324\n",
      "Epoch 47/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0112 - acc: 0.9963 - val_loss: 0.3347 - val_acc: 0.9341\n",
      "Epoch 48/200\n",
      "672/672 [==============================] - 414s 616ms/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.3506 - val_acc: 0.9317\n",
      "Epoch 49/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.3990 - val_acc: 0.9183\n",
      "Epoch 50/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0105 - acc: 0.9963 - val_loss: 0.3612 - val_acc: 0.9302\n",
      "Epoch 51/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.4216 - val_acc: 0.9180\n",
      "Epoch 52/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0097 - acc: 0.9970 - val_loss: 0.3393 - val_acc: 0.9332\n",
      "Epoch 53/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.3533 - val_acc: 0.9291\n",
      "Epoch 54/200\n",
      "672/672 [==============================] - 410s 611ms/step - loss: 0.0081 - acc: 0.9970 - val_loss: 0.3531 - val_acc: 0.9334\n",
      "Epoch 55/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.4033 - val_acc: 0.9252\n",
      "Epoch 56/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.3823 - val_acc: 0.9274\n",
      "Epoch 57/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.4001 - val_acc: 0.9240\n",
      "Epoch 58/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.3980 - val_acc: 0.9231\n",
      "Epoch 59/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0073 - acc: 0.9975 - val_loss: 0.3717 - val_acc: 0.9294\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.3958 - val_acc: 0.9244\n",
      "Epoch 61/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.0088 - acc: 0.9970 - val_loss: 0.3826 - val_acc: 0.9292\n",
      "Epoch 62/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.3661 - val_acc: 0.9307\n",
      "Epoch 63/200\n",
      "672/672 [==============================] - 411s 611ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.3596 - val_acc: 0.9329\n",
      "Epoch 64/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.3753 - val_acc: 0.9335\n",
      "Epoch 65/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.4290 - val_acc: 0.9225\n",
      "Epoch 66/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0078 - acc: 0.9975 - val_loss: 0.3739 - val_acc: 0.9343\n",
      "Epoch 67/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0074 - acc: 0.9973 - val_loss: 0.3972 - val_acc: 0.9296\n",
      "Epoch 68/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.3989 - val_acc: 0.9289\n",
      "Epoch 69/200\n",
      "672/672 [==============================] - 409s 609ms/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.3751 - val_acc: 0.9297\n",
      "Epoch 70/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.4872 - val_acc: 0.9124\n",
      "Epoch 71/200\n",
      "672/672 [==============================] - 414s 615ms/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.4384 - val_acc: 0.9208\n",
      "Epoch 72/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.4218 - val_acc: 0.9254\n",
      "Epoch 73/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.3770 - val_acc: 0.9350\n",
      "Epoch 74/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.4021 - val_acc: 0.9310\n",
      "Epoch 75/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0057 - acc: 0.9978 - val_loss: 0.4586 - val_acc: 0.9213\n",
      "Epoch 76/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.3984 - val_acc: 0.9312\n",
      "Epoch 77/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.3840 - val_acc: 0.9323\n",
      "Epoch 78/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0061 - acc: 0.9977 - val_loss: 0.4163 - val_acc: 0.9263\n",
      "Epoch 79/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.3825 - val_acc: 0.9340\n",
      "Epoch 80/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.4018 - val_acc: 0.9296\n",
      "Epoch 81/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0084 - acc: 0.9973 - val_loss: 0.4044 - val_acc: 0.9274\n",
      "Epoch 82/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.4073 - val_acc: 0.9281\n",
      "Epoch 83/200\n",
      "672/672 [==============================] - 426s 633ms/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.3909 - val_acc: 0.9304\n",
      "Epoch 84/200\n",
      "672/672 [==============================] - 412s 612ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.4136 - val_acc: 0.9267\n",
      "Epoch 85/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.3841 - val_acc: 0.9308\n",
      "Epoch 86/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.3851 - val_acc: 0.9316\n",
      "Epoch 87/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.3662 - val_acc: 0.9352\n",
      "Epoch 88/200\n",
      "672/672 [==============================] - 414s 616ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.4042 - val_acc: 0.9287\n",
      "Epoch 89/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.4384 - val_acc: 0.9223\n",
      "Epoch 90/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.3755 - val_acc: 0.9321\n",
      "Epoch 91/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.3918 - val_acc: 0.9311\n",
      "Epoch 92/200\n",
      "672/672 [==============================] - 412s 612ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.4120 - val_acc: 0.9275\n",
      "Epoch 93/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.3847 - val_acc: 0.9328\n",
      "Epoch 94/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.4045 - val_acc: 0.9276\n",
      "Epoch 95/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.4572 - val_acc: 0.9224\n",
      "Epoch 96/200\n",
      "672/672 [==============================] - 429s 638ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.4111 - val_acc: 0.9280\n",
      "Epoch 97/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.4208 - val_acc: 0.9289\n",
      "Epoch 98/200\n",
      "672/672 [==============================] - 410s 611ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.4320 - val_acc: 0.9268\n",
      "Epoch 99/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.4402 - val_acc: 0.9253\n",
      "Epoch 100/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.4302 - val_acc: 0.9276\n",
      "Epoch 101/200\n",
      "672/672 [==============================] - 411s 612ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.4306 - val_acc: 0.9281\n",
      "Epoch 102/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.3787 - val_acc: 0.9379\n",
      "Epoch 103/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.3668 - val_acc: 0.9352\n",
      "Epoch 104/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.3799 - val_acc: 0.9370\n",
      "Epoch 105/200\n",
      "672/672 [==============================] - 413s 614ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.4912 - val_acc: 0.9183\n",
      "Epoch 106/200\n",
      "672/672 [==============================] - 412s 614ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.4581 - val_acc: 0.9242\n",
      "Epoch 107/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.3808 - val_acc: 0.9350\n",
      "Epoch 108/200\n",
      "672/672 [==============================] - 412s 613ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.4087 - val_acc: 0.9320\n",
      "Epoch 109/200\n",
      "672/672 [==============================] - 413s 615ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.4275 - val_acc: 0.9282\n",
      "Epoch 110/200\n",
      "671/672 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2a84b20ca88e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                         callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m    198\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/site-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ecomed/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.device('/gpu:3'):\n",
    "    model.fit_generator(generator=train_generator,\n",
    "                        validation_data=validation_generator, \n",
    "                        epochs=200,\n",
    "                        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: ['train']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/bowen/Documents/Ecomed/models/model_big4/temp-b'1552404675'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/home/bowen/Documents/Ecomed/models/model_big4/1552404675'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.contrib.saved_model.save_keras_model(model, home_path + 'models/model_big4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
